{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "pd.options.display.max_columns = 50\n",
    "\n",
    "\n",
    "# Load dataset (iris), split into X_train, y_train, X_test, y_test!\n",
    "# Write your code here \n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :]\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    37\n",
       "1    37\n",
       "0    31\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Voting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Hint: \n",
    "# clf_voting = VotingClassifier( estimators=[('label1', clf_1),\n",
    "# ('label2', clf_2),\n",
    "# ('labelN', clf_N)]) \n",
    "\n",
    "# Create the individual models\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_lr = LogisticRegression()\n",
    "\n",
    "# Create voting classifier\n",
    "clf_voting = VotingClassifier(estimators=[\n",
    "('knn', clf_knn),\n",
    "('dt', clf_dt),\n",
    "('lr', clf_lr)])\n",
    "\n",
    "# Fit it to the training set and predict\n",
    "clf_voting.fit(X_train, y_train)\n",
    "y_pred = clf_voting.predict(X_test)\n",
    "\n",
    "# Get the accuracy score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:0.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "clf_knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_knn.predict(X_test)\n",
    "\n",
    "# Get the accuracy score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:0.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "clf_dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_dt.predict(X_test)\n",
    "\n",
    "# Get the accuracy score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:0.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.978\n"
     ]
    }
   ],
   "source": [
    "clf_lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_lr.predict(X_test)\n",
    "\n",
    "# Get the accuracy score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:0.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Averaging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Template for averaging Classifier \n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf_voting = VotingClassifier(estimators=[\n",
    "('knn', clf_knn),\n",
    "('dt', clf_dt),\n",
    "('lr', clf_lr)], voting=\"soft\")\n",
    "\n",
    "# Fit it to the training set and predict\n",
    "clf_voting.fit(X_train, y_train)\n",
    "y_pred = clf_voting.predict(X_test)\n",
    "\n",
    "# Get the accuracy score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:0.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initiate the individual models \n",
    "\n",
    "# Write your code here! \n",
    "\n",
    "# Create averaging classifier\n",
    "\n",
    "# Write your code here! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "bc = datasets.load_breast_cancer()\n",
    "\n",
    "X = bc.data[:, :]\n",
    "y = bc.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "bagging = BaggingClassifier(KNeighborsClassifier(),\n",
    "                           max_samples=0.5, max_features=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.627417\n",
       "0    0.372583\n",
       "dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.942\n"
     ]
    }
   ],
   "source": [
    "# Fit it to the training set and predict\n",
    "bagging.fit(X_train, y_train)\n",
    "y_pred = bagging.predict(X_test)\n",
    "\n",
    "\n",
    "# Get the accuracy score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:0.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.965\n"
     ]
    }
   ],
   "source": [
    "# Write your code here if you use RandomForest, compare with above!\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Fit it to the training set and predict\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "# Get the accuracy score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:0.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Boosting\n",
    "Source: https://scikit-learn.org/stable/modules/ensemble.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.936\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf_ada = AdaBoostClassifier(\n",
    "DecisionTreeClassifier(),\n",
    "n_estimators=75,\n",
    "learning_rate=0.2\n",
    ")\n",
    "\n",
    "# base_estimator\n",
    "# Default: Decision Tree (max_depth=1)\n",
    "# n_estimators\n",
    "# Default: 50\n",
    "# learning_rate\n",
    "# Default: 1.0\n",
    "# Trade-off between n_estimators and\n",
    "# learning_rate\n",
    "\n",
    "# Fit it to the training set and predict\n",
    "clf_ada.fit(X_train, y_train)\n",
    "y_pred = clf_ada.predict(X_test)\n",
    "\n",
    "\n",
    "# Get the accuracy score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:0.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AdaBoost Classifier for iris dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write your code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "clf_ada = AdaBoostRegressor(\n",
    "    DecisionTreeClassifier(),\n",
    "    n_estimators=75,\n",
    "    learning_rate=0.2\n",
    ")\n",
    "\n",
    "# base_estimator\n",
    "# Default: Decision Tree (max_depth=3)\n",
    "# loss\n",
    "# linear (default)\n",
    "# square\n",
    "# exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit it to the training set and predict\n",
    "clf_ada.fit(X_train, y_train)\n",
    "y_pred = clf_ada.predict(X_test)\n",
    "\n",
    "\n",
    "# Get the accuracy score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:0.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create GradientBoostingClassifier for iris Dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Using cached https://files.pythonhosted.org/packages/be/1e/69b342a7630d1d84cdf29cda07916081b0a45092fb1fea41a6a16589fe1c/catboost-0.18.1-cp36-none-win_amd64.whl\n",
      "Requirement already satisfied: plotly in d:\\anaconda\\lib\\site-packages (from catboost) (4.2.1)\n",
      "Requirement already satisfied: matplotlib in d:\\anaconda\\lib\\site-packages (from catboost) (3.1.1)\n",
      "Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from catboost) (0.19.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in d:\\anaconda\\lib\\site-packages (from catboost) (0.25.3)\n",
      "Collecting graphviz\n",
      "  Using cached https://files.pythonhosted.org/packages/f5/74/dbed754c0abd63768d3a7a7b472da35b08ac442cf87d73d5850a6f32391e/graphviz-0.13.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in d:\\anaconda\\lib\\site-packages (from catboost) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in d:\\anaconda\\lib\\site-packages (from catboost) (1.17.3)\n",
      "Requirement already satisfied: retrying>=1.3.3 in d:\\anaconda\\lib\\site-packages (from plotly->catboost) (1.3.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in d:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (2.6.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in d:\\anaconda\\lib\\site-packages (from pandas>=0.24.0->catboost) (2017.2)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (36.5.0.post20170921)\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-0.18.1 graphviz-0.13.2\n",
      "Requirement already satisfied: lightgbm in d:\\anaconda\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from lightgbm) (1.17.3)\n",
      "Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from lightgbm) (0.19.1)\n",
      "Requirement already satisfied: scikit-learn in d:\\anaconda\\lib\\site-packages (from lightgbm) (0.19.1)\n",
      "Requirement already satisfied: catboost in d:\\anaconda\\lib\\site-packages (0.18.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in d:\\anaconda\\lib\\site-packages (from catboost) (0.25.3)\n",
      "Requirement already satisfied: matplotlib in d:\\anaconda\\lib\\site-packages (from catboost) (3.1.1)\n",
      "Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from catboost) (0.19.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in d:\\anaconda\\lib\\site-packages (from catboost) (1.17.3)\n",
      "Requirement already satisfied: graphviz in d:\\anaconda\\lib\\site-packages (from catboost) (0.13.2)\n",
      "Requirement already satisfied: six in d:\\anaconda\\lib\\site-packages (from catboost) (1.11.0)\n",
      "Requirement already satisfied: plotly in d:\\anaconda\\lib\\site-packages (from catboost) (4.2.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in d:\\anaconda\\lib\\site-packages (from pandas>=0.24.0->catboost) (2017.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in d:\\anaconda\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.6.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (2.2.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in d:\\anaconda\\lib\\site-packages (from plotly->catboost) (1.3.3)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (36.5.0.post20170921)\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost\n",
    "!pip install lightgbm\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stacking  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.924\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the 1st-layer classifiers\n",
    "clf1 = KNeighborsClassifier(5)\n",
    "clf2 = DecisionTreeClassifier()\n",
    "clf3 = LogisticRegression()\n",
    "\n",
    "# Instantiate the 2nd-layer classifier\n",
    "clf_meta = LogisticRegression()\n",
    "\n",
    "# Build the Stacking classifier\n",
    "clf_stack = StackingClassifier(\n",
    "    classifiers=[clf1, clf2, clf3],\n",
    "    meta_classifier=clf_meta,\n",
    "    use_probas=False,\n",
    "    use_features_in_secondary=False\n",
    ")\n",
    "\n",
    "# Use the fit and predict methods\n",
    "clf_stack.fit(X_train, y_train)\n",
    "y_pred = clf_stack.predict(X_test)\n",
    "\n",
    "# Get the accuracy score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:0.3f}\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
